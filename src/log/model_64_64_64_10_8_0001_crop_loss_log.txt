Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6944210529327393
TrainLossEpoch0Step1: 0.7633850574493408
TrainLossEpoch0Step2: 0.6409268379211426
TrainLossEpoch0Step3: 0.7120110988616943
TrainLossEpoch0Step4: 0.610294759273529
TrainLossEpoch0Step5: 0.7051645517349243
TrainLossEpoch0Step6: 0.7234823703765869
TrainLossEpoch0Step7: 0.7468621730804443
TrainLossEpoch0Step8: 0.7198553085327148
TrainLossEpoch0Step9: 0.6638181805610657
TrainLossEpoch0Step10: 0.6990011930465698
TrainLossEpoch0Step11: 0.8139492273330688
TrainLossEpoch0Step12: 0.6682000756263733
TrainLossEpoch0Step13: 0.7195512056350708
TrainLossEpoch0Step14: 0.6774541139602661
TrainLossEpoch0Step15: 0.6880657076835632
TrainLossEpoch0Step16: 0.6535261273384094
TrainLossEpoch0Step17: 0.6301110982894897
TrainLossEpoch0Step18: 0.7041242122650146
TrainLossEpoch0Step19: 0.6841633915901184
TrainLossEpoch0Step20: 0.7777200937271118
TrainLossEpoch0Step21: 0.8016740083694458
TrainLossEpoch0Step22: 0.6431242227554321
TrainLossEpoch0Step23: 0.6887167692184448
TrainLossEpoch0Step24: 0.7211753129959106
TrainLossEpoch0Step25: 0.653302788734436
TrainLossEpoch0Step26: 0.7246302962303162
TrainLossEpoch0Step27: 0.7891053557395935
TrainLossEpoch0Step28: 0.7732743620872498
TrainLossEpoch0Step29: 0.6963803172111511
TrainLossEpoch0Step30: 0.6845983266830444
TrainLossEpoch0Step31: 0.7018407583236694
TrainLossEpoch0Step32: 0.739492654800415
TrainLossEpoch0Step33: 0.6899396181106567
TrainLossEpoch0Step34: 0.7156722545623779
TrainLossEpoch0Step35: 0.7246223092079163
TrainLossEpoch0Step36: 0.6479721069335938
TrainLossEpoch0Step37: 0.7223849296569824
TrainLossEpoch0Step38: 0.6499537825584412
TrainLossEpoch0Step39: 0.7669947147369385
TrainLossEpoch0Step40: 0.690858781337738
TrainLossEpoch0Step41: 0.765223503112793
TrainLossEpoch0Step42: 0.617387592792511
TrainLossEpoch0Step43: 0.8030916452407837
TrainLossEpoch0Step44: 0.6772955656051636
TrainLossEpoch0Step45: 0.7512614727020264
TrainLossEpoch0Step46: 0.6823321580886841
TrainLossEpoch0Step47: 0.630204439163208
TrainLossEpoch0Step48: 0.6559159755706787
TrainLossEpoch0Step49: 0.5868954658508301
TrainLossEpoch0Step50: 0.6793732643127441
TrainLossEpoch0Step51: 0.6770367622375488
TrainLossEpoch0Step52: 0.7891966104507446
TrainLossEpoch0Step53: 0.6668773889541626
TrainLossEpoch0Step54: 0.6967647075653076
TrainLossEpoch0Step55: 0.6479268670082092
TrainLossEpoch0Step56: 0.7196473479270935
TrainLossEpoch0Step57: 0.7346416711807251
TrainLossEpoch0Step58: 0.7074586153030396
TrainLossEpoch0Step59: 0.8000943660736084
TrainLossEpoch0Step60: 0.7139885425567627
TrainLossEpoch0Step61: 0.7922738790512085
TrainLossEpoch0Step62: 0.7371740341186523
TrainLossEpoch0Step63: 0.6900981068611145
TrainLossEpoch0Step64: 0.6494241952896118
TrainLossEpoch0Step65: 0.5911890268325806
TrainLossEpoch0Step66: 0.7042866945266724
TrainLossEpoch0Step67: 0.7069127559661865
TrainLossEpoch0Step68: 0.7356014251708984
TrainLossEpoch0Step69: 0.6931216716766357
TrainLossEpoch0, Amount pixel truth aneurysm: 81454
TrainLossEpoch0, Amount pixel predicted aneurysm: 256819
TrainLossEpoch0, Difference: 175365
TrainLossEpoch0, BCEWithLogitsLoss Mean: 0.7032071036951882
TrainLossEpoch1Step0: 0.717668890953064
TrainLossEpoch1Step1: 0.6456372737884521
TrainLossEpoch1Step2: 0.6728014945983887
TrainLossEpoch1Step3: 0.6230392456054688
TrainLossEpoch1Step4: 0.6337786912918091
TrainLossEpoch1Step5: 0.8022925853729248
TrainLossEpoch1Step6: 0.7259133458137512
TrainLossEpoch1Step7: 0.7426921129226685
TrainLossEpoch1Step8: 0.7885628342628479
TrainLossEpoch1Step9: 0.7046216726303101
TrainLossEpoch1Step10: 0.7223801612854004
TrainLossEpoch1Step11: 0.6500017642974854
TrainLossEpoch1Step12: 0.732502818107605
TrainLossEpoch1Step13: 0.6362166404724121
TrainLossEpoch1Step14: 0.6250512599945068
TrainLossEpoch1Step15: 0.7648815512657166
TrainLossEpoch1Step16: 0.712615966796875
TrainLossEpoch1Step17: 0.6287111043930054
TrainLossEpoch1Step18: 0.6220054626464844
TrainLossEpoch1Step19: 0.6669846773147583
TrainLossEpoch1Step20: 0.7147092819213867
TrainLossEpoch1Step21: 0.6894775629043579
TrainLossEpoch1Step22: 0.7184751629829407
TrainLossEpoch1Step23: 0.6795533895492554
TrainLossEpoch1Step24: 0.7182235717773438
TrainLossEpoch1Step25: 0.810840368270874
TrainLossEpoch1Step26: 0.5917598009109497
TrainLossEpoch1Step27: 0.5826953053474426
TrainLossEpoch1Step28: 0.5749799013137817
TrainLossEpoch1Step29: 0.6626065969467163
TrainLossEpoch1Step30: 0.7468777894973755
TrainLossEpoch1Step31: 0.7373241186141968
TrainLossEpoch1Step32: 0.7273809909820557
TrainLossEpoch1Step33: 0.6667135953903198
TrainLossEpoch1Step34: 0.6752386093139648
TrainLossEpoch1Step35: 0.69902503490448
TrainLossEpoch1Step36: 0.7689027786254883
TrainLossEpoch1Step37: 0.7375955581665039
TrainLossEpoch1Step38: 0.7663078308105469
TrainLossEpoch1Step39: 0.6417931318283081
TrainLossEpoch1Step40: 0.6610270142555237
TrainLossEpoch1Step41: 0.6599597334861755
TrainLossEpoch1Step42: 0.7016291618347168
TrainLossEpoch1Step43: 0.6640671491622925
TrainLossEpoch1Step44: 0.6389083862304688
TrainLossEpoch1Step45: 0.6694576740264893
TrainLossEpoch1Step46: 0.6975924968719482
TrainLossEpoch1Step47: 0.6916683316230774
TrainLossEpoch1Step48: 0.6925884485244751
TrainLossEpoch1Step49: 0.7398431301116943
TrainLossEpoch1Step50: 0.7461024522781372
TrainLossEpoch1Step51: 0.6866124868392944
TrainLossEpoch1Step52: 0.7213062047958374
TrainLossEpoch1Step53: 0.7411102652549744
TrainLossEpoch1Step54: 0.6887866854667664
TrainLossEpoch1Step55: 0.7986918687820435
TrainLossEpoch1Step56: 0.7323843240737915
TrainLossEpoch1Step57: 0.6888023018836975
TrainLossEpoch1Step58: 0.7033803462982178
TrainLossEpoch1Step59: 0.6851297616958618
TrainLossEpoch1Step60: 0.7248507142066956
TrainLossEpoch1Step61: 0.6136056184768677
TrainLossEpoch1Step62: 0.6794302463531494
TrainLossEpoch1Step63: 0.6063080430030823
TrainLossEpoch1Step64: 0.7042855024337769
TrainLossEpoch1Step65: 0.6499450206756592
TrainLossEpoch1Step66: 0.6034778356552124
TrainLossEpoch1Step67: 0.6767510175704956
TrainLossEpoch1Step68: 0.6888401508331299
TrainLossEpoch1Step69: 0.7723268270492554
TrainLossEpoch1, Amount pixel truth aneurysm: 81454
TrainLossEpoch1, Amount pixel predicted aneurysm: 115031
TrainLossEpoch1, Difference: 33577
TrainLossEpoch1, BCEWithLogitsLoss Mean: 0.6922529876232147
TrainLossEpoch2Step0: 0.6717051267623901
TrainLossEpoch2Step1: 0.6660822629928589
TrainLossEpoch2Step2: 0.6161921620368958
TrainLossEpoch2Step3: 0.71438068151474
TrainLossEpoch2Step4: 0.7605931758880615
TrainLossEpoch2Step5: 0.6337069869041443
TrainLossEpoch2Step6: 0.6487020254135132
TrainLossEpoch2Step7: 0.7213019728660583
TrainLossEpoch2Step8: 0.7220581769943237
TrainLossEpoch2Step9: 0.7236498594284058
TrainLossEpoch2Step10: 0.7085309028625488
TrainLossEpoch2Step11: 0.7011339664459229
TrainLossEpoch2Step12: 0.6361538171768188
TrainLossEpoch2Step13: 0.6391233205795288
TrainLossEpoch2Step14: 0.7695986032485962
TrainLossEpoch2Step15: 0.6824718713760376
TrainLossEpoch2Step16: 0.7721060514450073
TrainLossEpoch2Step17: 0.6929159164428711
TrainLossEpoch2Step18: 0.7368243336677551
TrainLossEpoch2Step19: 0.6318705081939697
TrainLossEpoch2Step20: 0.7413619756698608
TrainLossEpoch2Step21: 0.7529243230819702
TrainLossEpoch2Step22: 0.8043932914733887
TrainLossEpoch2Step23: 0.6435819268226624
TrainLossEpoch2Step24: 0.8155773282051086
TrainLossEpoch2Step25: 0.7725674510002136
TrainLossEpoch2Step26: 0.7130007147789001
TrainLossEpoch2Step27: 0.7168393731117249
TrainLossEpoch2Step28: 0.6671466827392578
TrainLossEpoch2Step29: 0.7847805023193359
TrainLossEpoch2Step30: 0.7039436101913452
TrainLossEpoch2Step31: 0.6649247407913208
TrainLossEpoch2Step32: 0.6523964405059814
TrainLossEpoch2Step33: 0.7438878417015076
TrainLossEpoch2Step34: 0.6679998636245728
TrainLossEpoch2Step35: 0.6138049364089966
TrainLossEpoch2Step36: 0.6519003510475159
TrainLossEpoch2Step37: 0.670793890953064
TrainLossEpoch2Step38: 0.7309016585350037
TrainLossEpoch2Step39: 0.6932922601699829
TrainLossEpoch2Step40: 0.7128902673721313
TrainLossEpoch2Step41: 0.6585814952850342
TrainLossEpoch2Step42: 0.8477592468261719
TrainLossEpoch2Step43: 0.6680830121040344
TrainLossEpoch2Step44: 0.7130345106124878
TrainLossEpoch2Step45: 0.6725784540176392
TrainLossEpoch2Step46: 0.6471877098083496
TrainLossEpoch2Step47: 0.7001535892486572
TrainLossEpoch2Step48: 0.6951217651367188
TrainLossEpoch2Step49: 0.753408670425415
TrainLossEpoch2Step50: 0.6969940066337585
TrainLossEpoch2Step51: 0.6483977437019348
TrainLossEpoch2Step52: 0.6704074144363403
TrainLossEpoch2Step53: 0.765776515007019
TrainLossEpoch2Step54: 0.645365297794342
TrainLossEpoch2Step55: 0.6334728002548218
TrainLossEpoch2Step56: 0.6696573495864868
TrainLossEpoch2Step57: 0.7012327909469604
TrainLossEpoch2Step58: 0.7184709310531616
TrainLossEpoch2Step59: 0.6983519792556763
TrainLossEpoch2Step60: 0.6375889778137207
TrainLossEpoch2Step61: 0.6508008241653442
TrainLossEpoch2Step62: 0.6527361869812012
TrainLossEpoch2Step63: 0.7450616955757141
TrainLossEpoch2Step64: 0.6668858528137207
TrainLossEpoch2Step65: 0.6168453693389893
TrainLossEpoch2Step66: 0.7719810009002686
TrainLossEpoch2Step67: 0.6715505719184875
TrainLossEpoch2Step68: 0.7243375778198242
TrainLossEpoch2Step69: 0.7481204271316528
TrainLossEpoch2, Amount pixel truth aneurysm: 81454
TrainLossEpoch2, Amount pixel predicted aneurysm: 272395
TrainLossEpoch2, Difference: 190941
TrainLossEpoch2, BCEWithLogitsLoss Mean: 0.6979707845619747
TrainLossEpoch3Step0: 0.6164278984069824
TrainLossEpoch3Step1: 0.7420969009399414
TrainLossEpoch3Step2: 0.71221923828125
TrainLossEpoch3Step3: 0.5963228940963745
TrainLossEpoch3Step4: 0.7199053168296814
TrainLossEpoch3Step5: 0.7213336229324341
TrainLossEpoch3Step6: 0.6372143030166626
TrainLossEpoch3Step7: 0.6661396622657776
TrainLossEpoch3Step8: 0.6821961402893066
TrainLossEpoch3Step9: 0.7442878484725952
TrainLossEpoch3Step10: 0.6705505847930908
TrainLossEpoch3Step11: 0.6595929861068726
TrainLossEpoch3Step12: 0.6885221600532532
TrainLossEpoch3Step13: 0.7558977603912354
TrainLossEpoch3Step14: 0.7081157565116882
TrainLossEpoch3Step15: 0.6428186893463135
TrainLossEpoch3Step16: 0.7419828176498413
TrainLossEpoch3Step17: 0.6235065460205078
TrainLossEpoch3Step18: 0.8103705644607544
TrainLossEpoch3Step19: 0.6936137676239014
TrainLossEpoch3Step20: 0.7588222622871399
TrainLossEpoch3Step21: 0.6835286617279053
TrainLossEpoch3Step22: 0.634109616279602
TrainLossEpoch3Step23: 0.6880772113800049
TrainLossEpoch3Step24: 0.7309561371803284
TrainLossEpoch3Step25: 0.6653730869293213
TrainLossEpoch3Step26: 0.6504027247428894
TrainLossEpoch3Step27: 0.6231697797775269
TrainLossEpoch3Step28: 0.7107922434806824
TrainLossEpoch3Step29: 0.634014368057251
TrainLossEpoch3Step30: 0.6554827690124512
TrainLossEpoch3Step31: 0.6410634517669678
TrainLossEpoch3Step32: 0.7109647393226624
TrainLossEpoch3Step33: 0.6956753730773926
TrainLossEpoch3Step34: 0.598444938659668
TrainLossEpoch3Step35: 0.6974512934684753
TrainLossEpoch3Step36: 0.7757127285003662
TrainLossEpoch3Step37: 0.6961731910705566
TrainLossEpoch3Step38: 0.6609446406364441
TrainLossEpoch3Step39: 0.7655302286148071
TrainLossEpoch3Step40: 0.652761697769165
TrainLossEpoch3Step41: 0.7228553295135498
TrainLossEpoch3Step42: 0.6428404450416565
TrainLossEpoch3Step43: 0.7249349355697632
TrainLossEpoch3Step44: 0.6488175392150879
TrainLossEpoch3Step45: 0.6497530937194824
TrainLossEpoch3Step46: 0.6257448792457581
TrainLossEpoch3Step47: 0.580562949180603
TrainLossEpoch3Step48: 0.6681818962097168
TrainLossEpoch3Step49: 0.615562379360199
TrainLossEpoch3Step50: 0.6787725687026978
TrainLossEpoch3Step51: 0.6782504320144653
TrainLossEpoch3Step52: 0.5609109401702881
TrainLossEpoch3Step53: 0.6632609963417053
TrainLossEpoch3Step54: 0.6643490791320801
TrainLossEpoch3Step55: 0.7169075012207031
TrainLossEpoch3Step56: 0.7964577674865723
TrainLossEpoch3Step57: 0.6982634663581848
TrainLossEpoch3Step58: 0.7109462022781372
TrainLossEpoch3Step59: 0.6527247428894043
TrainLossEpoch3Step60: 0.6527786254882812
TrainLossEpoch3Step61: 0.7318991422653198
TrainLossEpoch3Step62: 0.7136923670768738
TrainLossEpoch3Step63: 0.6541987657546997
TrainLossEpoch3Step64: 0.6744347214698792
TrainLossEpoch3Step65: 0.7293074131011963
TrainLossEpoch3Step66: 0.670311689376831
TrainLossEpoch3Step67: 0.6608172655105591
TrainLossEpoch3Step68: 0.6001067161560059
TrainLossEpoch3Step69: 0.723469614982605
TrainLossEpoch3, Amount pixel truth aneurysm: 81454
TrainLossEpoch3, Amount pixel predicted aneurysm: 149488
TrainLossEpoch3, Difference: 68034
TrainLossEpoch3, BCEWithLogitsLoss Mean: 0.6810525723866054
TrainLossEpoch4Step0: 0.5798016786575317
TrainLossEpoch4Step1: 0.7026824951171875
TrainLossEpoch4Step2: 0.6795891523361206
TrainLossEpoch4Step3: 0.7607342004776001
TrainLossEpoch4Step4: 0.6664303541183472
TrainLossEpoch4Step5: 0.7055116891860962
TrainLossEpoch4Step6: 0.7442715167999268
TrainLossEpoch4Step7: 0.6304765939712524
TrainLossEpoch4Step8: 0.688340425491333
TrainLossEpoch4Step9: 0.6206106543540955
TrainLossEpoch4Step10: 0.6955567598342896
TrainLossEpoch4Step11: 0.6974068880081177
TrainLossEpoch4Step12: 0.6702670454978943
TrainLossEpoch4Step13: 0.7031694650650024
TrainLossEpoch4Step14: 0.6755319833755493
TrainLossEpoch4Step15: 0.6726562976837158
TrainLossEpoch4Step16: 0.7418975830078125
TrainLossEpoch4Step17: 0.6511619687080383
TrainLossEpoch4Step18: 0.6773384213447571
TrainLossEpoch4Step19: 0.6799372434616089
TrainLossEpoch4Step20: 0.7020739912986755
TrainLossEpoch4Step21: 0.7852427959442139
TrainLossEpoch4Step22: 0.7823960781097412
TrainLossEpoch4Step23: 0.6839326620101929
TrainLossEpoch4Step24: 0.6245543956756592
TrainLossEpoch4Step25: 0.7813524603843689
TrainLossEpoch4Step26: 0.7177027463912964
TrainLossEpoch4Step27: 0.8055779933929443
TrainLossEpoch4Step28: 0.6773884296417236
TrainLossEpoch4Step29: 0.6601100564002991
TrainLossEpoch4Step30: 0.7192325592041016
TrainLossEpoch4Step31: 0.6787489652633667
TrainLossEpoch4Step32: 0.6801656484603882
TrainLossEpoch4Step33: 0.7117610573768616
TrainLossEpoch4Step34: 0.6299164295196533
TrainLossEpoch4Step35: 0.6279408931732178
TrainLossEpoch4Step36: 0.6998230218887329
TrainLossEpoch4Step37: 0.6108977794647217
TrainLossEpoch4Step38: 0.7442420721054077
TrainLossEpoch4Step39: 0.6872859001159668
TrainLossEpoch4Step40: 0.748724639415741
TrainLossEpoch4Step41: 0.772385835647583
TrainLossEpoch4Step42: 0.6992955803871155
TrainLossEpoch4Step43: 0.7093021869659424
TrainLossEpoch4Step44: 0.7412333488464355
TrainLossEpoch4Step45: 0.7515095472335815
TrainLossEpoch4Step46: 0.6535801887512207
TrainLossEpoch4Step47: 0.6937268972396851
TrainLossEpoch4Step48: 0.6884244680404663
TrainLossEpoch4Step49: 0.7300029993057251
TrainLossEpoch4Step50: 0.7110222578048706
TrainLossEpoch4Step51: 0.7745392322540283
TrainLossEpoch4Step52: 0.7320095896720886
TrainLossEpoch4Step53: 0.7334533929824829
TrainLossEpoch4Step54: 0.6221829056739807
TrainLossEpoch4Step55: 0.6773983240127563
TrainLossEpoch4Step56: 0.7106208801269531
TrainLossEpoch4Step57: 0.6255223751068115
TrainLossEpoch4Step58: 0.6863890886306763
TrainLossEpoch4Step59: 0.6363689303398132
TrainLossEpoch4Step60: 0.690812349319458
TrainLossEpoch4Step61: 0.6334058046340942
TrainLossEpoch4Step62: 0.6748096346855164
TrainLossEpoch4Step63: 0.7618021965026855
TrainLossEpoch4Step64: 0.7207156419754028
TrainLossEpoch4Step65: 0.674319863319397
TrainLossEpoch4Step66: 0.7260257601737976
TrainLossEpoch4Step67: 0.8208408355712891
TrainLossEpoch4Step68: 0.6309061050415039
TrainLossEpoch4Step69: 0.6646061539649963
TrainLossEpoch4, Amount pixel truth aneurysm: 81454
TrainLossEpoch4, Amount pixel predicted aneurysm: 159388
TrainLossEpoch4, Difference: 77934
TrainLossEpoch4, BCEWithLogitsLoss Mean: 0.696423648084913
TrainLossEpoch5Step0: 0.7329529523849487
TrainLossEpoch5Step1: 0.7694801688194275
TrainLossEpoch5Step2: 0.7424618601799011
TrainLossEpoch5Step3: 0.656505823135376
TrainLossEpoch5Step4: 0.6868034601211548
TrainLossEpoch5Step5: 0.6760306358337402
TrainLossEpoch5Step6: 0.7460123896598816
TrainLossEpoch5Step7: 0.7036763429641724
TrainLossEpoch5Step8: 0.6860881447792053
TrainLossEpoch5Step9: 0.7393781542778015
TrainLossEpoch5Step10: 0.6871246099472046
TrainLossEpoch5Step11: 0.7132546901702881
TrainLossEpoch5Step12: 0.6548998951911926
TrainLossEpoch5Step13: 0.7399686574935913
TrainLossEpoch5Step14: 0.7143588662147522
TrainLossEpoch5Step15: 0.6736155152320862
TrainLossEpoch5Step16: 0.6566616296768188
TrainLossEpoch5Step17: 0.7524825930595398
TrainLossEpoch5Step18: 0.724912166595459
TrainLossEpoch5Step19: 0.5426993370056152
TrainLossEpoch5Step20: 0.6877883672714233
TrainLossEpoch5Step21: 0.6668564081192017
TrainLossEpoch5Step22: 0.6921969652175903
TrainLossEpoch5Step23: 0.6925559043884277
TrainLossEpoch5Step24: 0.6299119591712952
TrainLossEpoch5Step25: 0.7627758979797363
TrainLossEpoch5Step26: 0.7973507642745972
TrainLossEpoch5Step27: 0.6575707197189331
TrainLossEpoch5Step28: 0.7560251355171204
TrainLossEpoch5Step29: 0.7159067392349243
TrainLossEpoch5Step30: 0.7933909893035889
TrainLossEpoch5Step31: 0.7845547199249268
TrainLossEpoch5Step32: 0.7600850462913513
TrainLossEpoch5Step33: 0.6270686388015747
TrainLossEpoch5Step34: 0.7387473583221436
TrainLossEpoch5Step35: 0.7715001106262207
TrainLossEpoch5Step36: 0.6793434023857117
TrainLossEpoch5Step37: 0.7383960485458374
TrainLossEpoch5Step38: 0.6432565450668335
TrainLossEpoch5Step39: 0.7859797477722168
TrainLossEpoch5Step40: 0.6838107109069824
TrainLossEpoch5Step41: 0.6713488101959229
TrainLossEpoch5Step42: 0.7222738265991211
TrainLossEpoch5Step43: 0.7526465654373169
TrainLossEpoch5Step44: 0.7160439491271973
TrainLossEpoch5Step45: 0.6624158620834351
TrainLossEpoch5Step46: 0.7584958672523499
TrainLossEpoch5Step47: 0.6956126093864441
TrainLossEpoch5Step48: 0.7374145984649658
TrainLossEpoch5Step49: 0.7194473743438721
TrainLossEpoch5Step50: 0.6977910399436951
TrainLossEpoch5Step51: 0.7237991094589233
TrainLossEpoch5Step52: 0.8434616327285767
TrainLossEpoch5Step53: 0.7413104176521301
TrainLossEpoch5Step54: 0.715287446975708
TrainLossEpoch5Step55: 0.6644740700721741
TrainLossEpoch5Step56: 0.6771570444107056
TrainLossEpoch5Step57: 0.6373509168624878
TrainLossEpoch5Step58: 0.6352578997612
TrainLossEpoch5Step59: 0.7083415985107422
TrainLossEpoch5Step60: 0.646609902381897
TrainLossEpoch5Step61: 0.7560702562332153
TrainLossEpoch5Step62: 0.7204466462135315
TrainLossEpoch5Step63: 0.6547940373420715
TrainLossEpoch5Step64: 0.7071247100830078
TrainLossEpoch5Step65: 0.7145789861679077
TrainLossEpoch5Step66: 0.7302643060684204
TrainLossEpoch5Step67: 0.6879047155380249
TrainLossEpoch5Step68: 0.6827036142349243
TrainLossEpoch5Step69: 0.6795003414154053
TrainLossEpoch5, Amount pixel truth aneurysm: 81454
TrainLossEpoch5, Amount pixel predicted aneurysm: 194583
TrainLossEpoch5, Difference: 113129
TrainLossEpoch5, BCEWithLogitsLoss Mean: 0.7074909746646881
TrainLossEpoch6Step0: 0.6931473016738892
TrainLossEpoch6Step1: 0.731968879699707
TrainLossEpoch6Step2: 0.7247004508972168
TrainLossEpoch6Step3: 0.6727590560913086
TrainLossEpoch6Step4: 0.7571542263031006
TrainLossEpoch6Step5: 0.6867942214012146
TrainLossEpoch6Step6: 0.6615065932273865
TrainLossEpoch6Step7: 0.7180598974227905
TrainLossEpoch6Step8: 0.6929755806922913
TrainLossEpoch6Step9: 0.73029625415802
TrainLossEpoch6Step10: 0.7168220281600952
TrainLossEpoch6Step11: 0.6252315640449524
TrainLossEpoch6Step12: 0.6860647797584534
TrainLossEpoch6Step13: 0.6869269609451294
TrainLossEpoch6Step14: 0.6385560035705566
TrainLossEpoch6Step15: 0.7308461666107178
TrainLossEpoch6Step16: 0.6455777883529663
TrainLossEpoch6Step17: 0.7420415282249451
TrainLossEpoch6Step18: 0.7336759567260742
TrainLossEpoch6Step19: 0.7530462145805359
TrainLossEpoch6Step20: 0.6870302557945251
TrainLossEpoch6Step21: 0.703438401222229
TrainLossEpoch6Step22: 0.7131418585777283
TrainLossEpoch6Step23: 0.7259941697120667
TrainLossEpoch6Step24: 0.7527149319648743
TrainLossEpoch6Step25: 0.6587690711021423
TrainLossEpoch6Step26: 0.719836950302124
TrainLossEpoch6Step27: 0.8354047536849976
TrainLossEpoch6Step28: 0.6760143041610718
TrainLossEpoch6Step29: 0.6745058298110962
TrainLossEpoch6Step30: 0.6797568798065186
TrainLossEpoch6Step31: 0.6477243304252625
TrainLossEpoch6Step32: 0.720146119594574
TrainLossEpoch6Step33: 0.648925244808197
TrainLossEpoch6Step34: 0.6122233867645264
TrainLossEpoch6Step35: 0.6770122051239014
TrainLossEpoch6Step36: 0.690737247467041
TrainLossEpoch6Step37: 0.7351068258285522
TrainLossEpoch6Step38: 0.6835068464279175
TrainLossEpoch6Step39: 0.6551574468612671
TrainLossEpoch6Step40: 0.6235742568969727
TrainLossEpoch6Step41: 0.6973453760147095
TrainLossEpoch6Step42: 0.6364268064498901
TrainLossEpoch6Step43: 0.666040301322937
TrainLossEpoch6Step44: 0.7319005727767944
TrainLossEpoch6Step45: 0.6178585290908813
TrainLossEpoch6Step46: 0.7654857635498047
TrainLossEpoch6Step47: 0.748696506023407
TrainLossEpoch6Step48: 0.6988663673400879
TrainLossEpoch6Step49: 0.662652313709259
TrainLossEpoch6Step50: 0.7794097661972046
TrainLossEpoch6Step51: 0.7118054628372192
TrainLossEpoch6Step52: 0.7435517311096191
TrainLossEpoch6Step53: 0.710404634475708
TrainLossEpoch6Step54: 0.694097101688385
TrainLossEpoch6Step55: 0.7450358867645264
TrainLossEpoch6Step56: 0.7570041418075562
TrainLossEpoch6Step57: 0.5801452994346619
TrainLossEpoch6Step58: 0.661157488822937
TrainLossEpoch6Step59: 0.7379246950149536
TrainLossEpoch6Step60: 0.7969129085540771
TrainLossEpoch6Step61: 0.6067073941230774
TrainLossEpoch6Step62: 0.7160435318946838
TrainLossEpoch6Step63: 0.8204753398895264
TrainLossEpoch6Step64: 0.7135649919509888
TrainLossEpoch6Step65: 0.5938345193862915
TrainLossEpoch6Step66: 0.7023679614067078
TrainLossEpoch6Step67: 0.6954963207244873
TrainLossEpoch6Step68: 0.682355523109436
TrainLossEpoch6Step69: 0.7371516227722168
TrainLossEpoch6, Amount pixel truth aneurysm: 81454
TrainLossEpoch6, Amount pixel predicted aneurysm: 148651
TrainLossEpoch6, Difference: 67197
TrainLossEpoch6, BCEWithLogitsLoss Mean: 0.6994227375302996
TrainLossEpoch7Step0: 0.6167746782302856
TrainLossEpoch7Step1: 0.656861424446106
TrainLossEpoch7Step2: 0.6478068232536316
TrainLossEpoch7Step3: 0.7226071357727051
TrainLossEpoch7Step4: 0.7656249403953552
TrainLossEpoch7Step5: 0.6860063076019287
TrainLossEpoch7Step6: 0.635797381401062
TrainLossEpoch7Step7: 0.6731619834899902
TrainLossEpoch7Step8: 0.6393691301345825
TrainLossEpoch7Step9: 0.6755965948104858
TrainLossEpoch7Step10: 0.64659583568573
TrainLossEpoch7Step11: 0.6535709500312805
TrainLossEpoch7Step12: 0.7485946416854858
TrainLossEpoch7Step13: 0.6664974689483643
TrainLossEpoch7Step14: 0.7380597591400146
TrainLossEpoch7Step15: 0.6416810750961304
TrainLossEpoch7Step16: 0.6970943212509155
TrainLossEpoch7Step17: 0.6749769449234009
TrainLossEpoch7Step18: 0.7568477988243103
TrainLossEpoch7Step19: 0.7312951683998108
TrainLossEpoch7Step20: 0.7284328937530518
TrainLossEpoch7Step21: 0.676829993724823
TrainLossEpoch7Step22: 0.6842321157455444
TrainLossEpoch7Step23: 0.6534662246704102
TrainLossEpoch7Step24: 0.716237485408783
TrainLossEpoch7Step25: 0.726281464099884
TrainLossEpoch7Step26: 0.6443518400192261
TrainLossEpoch7Step27: 0.6371992230415344
TrainLossEpoch7Step28: 0.6313328742980957
TrainLossEpoch7Step29: 0.7353470325469971
TrainLossEpoch7Step30: 0.7315577268600464
TrainLossEpoch7Step31: 0.6579596996307373
TrainLossEpoch7Step32: 0.7275317907333374
TrainLossEpoch7Step33: 0.6800962686538696
TrainLossEpoch7Step34: 0.6946762800216675
TrainLossEpoch7Step35: 0.6946854591369629
TrainLossEpoch7Step36: 0.7330676317214966
TrainLossEpoch7Step37: 0.6640921235084534
TrainLossEpoch7Step38: 0.8217395544052124
TrainLossEpoch7Step39: 0.6336575746536255
TrainLossEpoch7Step40: 0.7052690982818604
TrainLossEpoch7Step41: 0.7542483806610107
TrainLossEpoch7Step42: 0.7203073501586914
TrainLossEpoch7Step43: 0.6550276279449463
TrainLossEpoch7Step44: 0.6958776712417603
TrainLossEpoch7Step45: 0.6437914371490479
TrainLossEpoch7Step46: 0.6555590629577637
TrainLossEpoch7Step47: 0.803973913192749
TrainLossEpoch7Step48: 0.5878247022628784
TrainLossEpoch7Step49: 0.6908870339393616
TrainLossEpoch7Step50: 0.5794773101806641
TrainLossEpoch7Step51: 0.6039320230484009
TrainLossEpoch7Step52: 0.7224946022033691
TrainLossEpoch7Step53: 0.7307272553443909
TrainLossEpoch7Step54: 0.7441370487213135
TrainLossEpoch7Step55: 0.688462495803833
TrainLossEpoch7Step56: 0.6846951246261597
TrainLossEpoch7Step57: 0.7641627788543701
TrainLossEpoch7Step58: 0.7612634897232056
TrainLossEpoch7Step59: 0.7497910261154175
TrainLossEpoch7Step60: 0.8017944097518921
TrainLossEpoch7Step61: 0.7991980314254761
TrainLossEpoch7Step62: 0.7052532434463501
TrainLossEpoch7Step63: 0.7269840240478516
TrainLossEpoch7Step64: 0.7065912485122681
TrainLossEpoch7Step65: 0.6983367204666138
TrainLossEpoch7Step66: 0.6708965301513672
TrainLossEpoch7Step67: 0.6333495378494263
TrainLossEpoch7Step68: 0.6216915845870972
TrainLossEpoch7Step69: 0.6813070178031921
TrainLossEpoch7, Amount pixel truth aneurysm: 81454
TrainLossEpoch7, Amount pixel predicted aneurysm: 188088
TrainLossEpoch7, Difference: 106634
TrainLossEpoch7, BCEWithLogitsLoss Mean: 0.6933558200086866
TrainLossEpoch8Step0: 0.6388100385665894
TrainLossEpoch8Step1: 0.7213737964630127
TrainLossEpoch8Step2: 0.7684828042984009
TrainLossEpoch8Step3: 0.6576609015464783
TrainLossEpoch8Step4: 0.71172034740448
TrainLossEpoch8Step5: 0.7163701057434082
TrainLossEpoch8Step6: 0.6828911304473877
TrainLossEpoch8Step7: 0.6975336074829102
TrainLossEpoch8Step8: 0.7652000188827515
TrainLossEpoch8Step9: 0.7165555953979492
TrainLossEpoch8Step10: 0.663713812828064
TrainLossEpoch8Step11: 0.7402819395065308
TrainLossEpoch8Step12: 0.7429953813552856
TrainLossEpoch8Step13: 0.7318875789642334
TrainLossEpoch8Step14: 0.6325511932373047
TrainLossEpoch8Step15: 0.6620527505874634
TrainLossEpoch8Step16: 0.641299843788147
TrainLossEpoch8Step17: 0.7180088758468628
TrainLossEpoch8Step18: 0.7407655715942383
TrainLossEpoch8Step19: 0.6682707071304321
TrainLossEpoch8Step20: 0.6155165433883667
TrainLossEpoch8Step21: 0.7162591218948364
TrainLossEpoch8Step22: 0.7020893096923828
TrainLossEpoch8Step23: 0.8379238843917847
TrainLossEpoch8Step24: 0.6525626182556152
TrainLossEpoch8Step25: 0.7726807594299316
TrainLossEpoch8Step26: 0.6900534629821777
TrainLossEpoch8Step27: 0.6955809593200684
TrainLossEpoch8Step28: 0.6861157417297363
TrainLossEpoch8Step29: 0.6569981575012207
TrainLossEpoch8Step30: 0.7224245071411133
TrainLossEpoch8Step31: 0.699718713760376
TrainLossEpoch8Step32: 0.7833732962608337
TrainLossEpoch8Step33: 0.6158866882324219
TrainLossEpoch8Step34: 0.7119715213775635
TrainLossEpoch8Step35: 0.7718966603279114
TrainLossEpoch8Step36: 0.6157152652740479
TrainLossEpoch8Step37: 0.6592451333999634
TrainLossEpoch8Step38: 0.7026981115341187
TrainLossEpoch8Step39: 0.6459965705871582
TrainLossEpoch8Step40: 0.7197043895721436
TrainLossEpoch8Step41: 0.6941094994544983
TrainLossEpoch8Step42: 0.7148821353912354
TrainLossEpoch8Step43: 0.639352560043335
TrainLossEpoch8Step44: 0.7300148606300354
TrainLossEpoch8Step45: 0.6189929246902466
TrainLossEpoch8Step46: 0.641926646232605
TrainLossEpoch8Step47: 0.7026286125183105
TrainLossEpoch8Step48: 0.6757956743240356
TrainLossEpoch8Step49: 0.6716925501823425
TrainLossEpoch8Step50: 0.6151944994926453
TrainLossEpoch8Step51: 0.690688967704773
TrainLossEpoch8Step52: 0.7229030132293701
TrainLossEpoch8Step53: 0.7889019250869751
TrainLossEpoch8Step54: 0.6539298295974731
TrainLossEpoch8Step55: 0.6377125978469849
TrainLossEpoch8Step56: 0.7312166690826416
TrainLossEpoch8Step57: 0.6834889650344849
TrainLossEpoch8Step58: 0.6787861585617065
TrainLossEpoch8Step59: 0.7083936929702759
TrainLossEpoch8Step60: 0.6894397735595703
TrainLossEpoch8Step61: 0.7533212304115295
TrainLossEpoch8Step62: 0.7127206921577454
TrainLossEpoch8Step63: 0.7604451179504395
TrainLossEpoch8Step64: 0.5941284894943237
TrainLossEpoch8Step65: 0.6999906301498413
TrainLossEpoch8Step66: 0.6852656006813049
TrainLossEpoch8Step67: 0.6826574802398682
TrainLossEpoch8Step68: 0.6735954284667969
TrainLossEpoch8Step69: 0.6992747783660889
TrainLossEpoch8, Amount pixel truth aneurysm: 81454
TrainLossEpoch8, Amount pixel predicted aneurysm: 139477
TrainLossEpoch8, Difference: 58023
TrainLossEpoch8, BCEWithLogitsLoss Mean: 0.694918406009674
TrainLossEpoch9Step0: 0.6376050114631653
TrainLossEpoch9Step1: 0.7354134321212769
TrainLossEpoch9Step2: 0.6826385259628296
TrainLossEpoch9Step3: 0.6349018812179565
TrainLossEpoch9Step4: 0.7489066123962402
TrainLossEpoch9Step5: 0.6411685943603516
TrainLossEpoch9Step6: 0.6741710901260376
TrainLossEpoch9Step7: 0.6768938302993774
TrainLossEpoch9Step8: 0.662887454032898
TrainLossEpoch9Step9: 0.7618683576583862
TrainLossEpoch9Step10: 0.6827415227890015
TrainLossEpoch9Step11: 0.5998085141181946
TrainLossEpoch9Step12: 0.6563501954078674
TrainLossEpoch9Step13: 0.6732032299041748
TrainLossEpoch9Step14: 0.6982345581054688
TrainLossEpoch9Step15: 0.6708170175552368
TrainLossEpoch9Step16: 0.7130143642425537
TrainLossEpoch9Step17: 0.6222084760665894
TrainLossEpoch9Step18: 0.6919939517974854
TrainLossEpoch9Step19: 0.7105636596679688
TrainLossEpoch9Step20: 0.673098623752594
TrainLossEpoch9Step21: 0.7305434942245483
TrainLossEpoch9Step22: 0.6882590055465698
TrainLossEpoch9Step23: 0.759145975112915
TrainLossEpoch9Step24: 0.6739658117294312
TrainLossEpoch9Step25: 0.6159265041351318
TrainLossEpoch9Step26: 0.6762038469314575
TrainLossEpoch9Step27: 0.698912501335144
TrainLossEpoch9Step28: 0.769612193107605
TrainLossEpoch9Step29: 0.7481057643890381
TrainLossEpoch9Step30: 0.7779532670974731
TrainLossEpoch9Step31: 0.6461687684059143
TrainLossEpoch9Step32: 0.6631113290786743
TrainLossEpoch9Step33: 0.6709572672843933
TrainLossEpoch9Step34: 0.730218768119812
TrainLossEpoch9Step35: 0.6594561338424683
TrainLossEpoch9Step36: 0.7005106210708618
TrainLossEpoch9Step37: 0.8144612908363342
TrainLossEpoch9Step38: 0.7541109323501587
TrainLossEpoch9Step39: 0.6184142827987671
TrainLossEpoch9Step40: 0.7503331899642944
TrainLossEpoch9Step41: 0.6853482127189636
TrainLossEpoch9Step42: 0.7052080631256104
TrainLossEpoch9Step43: 0.7932454347610474
TrainLossEpoch9Step44: 0.6771383881568909
TrainLossEpoch9Step45: 0.7755871415138245
TrainLossEpoch9Step46: 0.7359133958816528
TrainLossEpoch9Step47: 0.7139670848846436
TrainLossEpoch9Step48: 0.6858454942703247
TrainLossEpoch9Step49: 0.7615267634391785
TrainLossEpoch9Step50: 0.6315351724624634
TrainLossEpoch9Step51: 0.6749893426895142
TrainLossEpoch9Step52: 0.8083795309066772
TrainLossEpoch9Step53: 0.6740490794181824
TrainLossEpoch9Step54: 0.6324847340583801
TrainLossEpoch9Step55: 0.7020336389541626
TrainLossEpoch9Step56: 0.7100877165794373
TrainLossEpoch9Step57: 0.6321640610694885
TrainLossEpoch9Step58: 0.6492362022399902
TrainLossEpoch9Step59: 0.6203639507293701
TrainLossEpoch9Step60: 0.7763150930404663
TrainLossEpoch9Step61: 0.5568935871124268
TrainLossEpoch9Step62: 0.7276524305343628
TrainLossEpoch9Step63: 0.7071452140808105
TrainLossEpoch9Step64: 0.7371994256973267
TrainLossEpoch9Step65: 0.7055993676185608
TrainLossEpoch9Step66: 0.6845971345901489
TrainLossEpoch9Step67: 0.7016292214393616
TrainLossEpoch9Step68: 0.772643506526947
TrainLossEpoch9Step69: 0.7817795276641846
TrainLossEpoch9, Amount pixel truth aneurysm: 81454
TrainLossEpoch9, Amount pixel predicted aneurysm: 196198
TrainLossEpoch9, Difference: 114744
TrainLossEpoch9, BCEWithLogitsLoss Mean: 0.6973631109510149
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.738811731338501
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6888314485549927
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6413464546203613
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.7381024956703186
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6818268895149231
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.7084418535232544
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6627235412597656
TrainLossEpoch0Step1: 0.7232781648635864
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6467311978340149
TrainLossEpoch0Step1: 0.7410562634468079
TrainLossEpoch0Step2: 0.7616722583770752
TrainLossEpoch0Step3: 0.6734714508056641
Log file start for the test: model_64_64_64_10_8_0001_crop_loss_log.txt
TrainLossEpoch0Step0: 0.6799485683441162
